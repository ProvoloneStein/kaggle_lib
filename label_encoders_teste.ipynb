{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "label_encoders_teste.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pasr9jkghk4e"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqPSY2KV9oQh"
      },
      "source": [
        "!pip install feature-engine\n",
        "!pip install category_encoders\n",
        "!pip install shap\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBno8c-E9tP0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from category_encoders import *\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from feature_engine import categorical_encoders as ce\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.base import clone\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import check_cv, KFold\n",
        "from category_encoders import CatBoostEncoder\n",
        "import shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUradsKp-h0L"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() #this will prompt you to update the json\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pasr9jkghk4e"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvK7bdPgqqQS"
      },
      "source": [
        "## models_test\n",
        "  Строятся модели Logreg and RandomForest\n",
        "  \n",
        "  model_type - тип модели. По стандарту Logreg\n",
        "    \n",
        "    1 - Logreg\n",
        "    2 - RandomForest\n",
        "  en_type тип эндкодинга(для вывода)\n",
        "\n",
        " Пример:\n",
        "\n",
        "  models_test(X_train, X_test, y_train, y_test, en_type='catboost')\n",
        "\n",
        "  -> catboost LogisticRegression ROC_AUC= 0.70414"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3re4jkprOM0"
      },
      "source": [
        "def models_test(X_train, X_test, y_train, y_test, model_type=1, en_type='TEST', _plots=False): \n",
        "\n",
        "  if model_type == 1:\n",
        "      clf=LogisticRegression(C=1, solver=\"lbfgs\", max_iter=5000) \n",
        "      clf.fit(X_train, y_train)\n",
        "      print(en_type, 'LogisticRegression ROC_AUC=', \n",
        "            metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
        "      vectorizer = TfidfVectorizer(min_df=10)\n",
        "      xplainer = shap.Explainer(clf, X_train, feature_names=vectorizer.get_feature_names())\n",
        "      shap_values = explainer(X_test)\n",
        "      if _plots:\n",
        "        make_feature_plot(X_train, 'LogisticRegression', en_type, clf.coef_[0])\n",
        "  elif model_type == 2:\n",
        "    rfr = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
        "    rfr.fit(X_train, y_train)\n",
        "    print(en_type, 'RandomForest ROC_AUC=',\n",
        "          metrics.roc_auc_score(y_test, rfr.predict(X_test)))\n",
        "    if _plots:\n",
        "      make_feature_plot(X_train, 'RandomForestRegressor', en_type, rfr.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXCzBCplx9cm"
      },
      "source": [
        "## make_feature_plot\n",
        "Делает график по фичам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH-VRA9kx6Sm"
      },
      "source": [
        "def make_feature_plot(df, model_type, en_type, f_coefs):\n",
        "    feature_importance = abs(f_coefs)\n",
        "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "    sorted_idx = np.argsort(feature_importance)\n",
        "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "    featfig = plt.figure()\n",
        "    featax = featfig.add_subplot(1, 1, 1)\n",
        "    featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "    featax.set_yticks(pos)\n",
        "    featax.set_yticklabels(np.array(df.columns)[sorted_idx], fontsize=8)\n",
        "    featax.set_xlabel(f'{model_type} {en_type} Relative Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0Z1WuehpYz"
      },
      "source": [
        "## encode_ohe \n",
        "меняет данные с помощью OneHotEncoder - разбивает категориальные переменные на бинарные переменные принадлежности к категории\n",
        "\n",
        "df - DataFrame\n",
        "\n",
        "cols колонки, к которым применить"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8P_Jg1SZalV"
      },
      "source": [
        "def encode_ohe(X_train, X_test, cols):\n",
        "  # Produces 1,0 data columns corresponding to all the unique categorical entries in col columns list\n",
        "  \n",
        "  col_names = []\n",
        "  \n",
        "  for i in cols:\n",
        "    for j in X_train[i].unique():\n",
        "      col_names.append(f\"{i}_{j}\")\n",
        "\n",
        "  OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "  OH_train = pd.DataFrame(OH_encoder.fit_transform(X_train[cols]), columns=col_names)\n",
        "  OH_test = pd.DataFrame(OH_encoder.transform(X_test[cols]), columns=col_names)\n",
        "  # OH encoding removes index in the data set. Putting the index back again\n",
        "  OH_train.index = X_train.index\n",
        "  OH_test.index = X_test.index\n",
        "  # Remove cols columns (will replace with one-hot encoding)\n",
        "  temp_train = X_train.drop(cols, axis=1)\n",
        "  temp_test = X_test.drop(cols, axis=1)\n",
        "  # Add one-hot encoded columns to the original data\n",
        "  X_train = pd.concat([temp_train, OH_train], axis=1)\n",
        "  X_test = pd.concat([temp_test, OH_test], axis=1)\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zicWmxzcj5ln"
      },
      "source": [
        "## encode_rare\n",
        "Group rare categories\n",
        "df - DataFrame\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "min_valut минимальная частота категории, иначе не значима => группируется\n",
        "\n",
        "n_cat минимальное число категорий. если меньше - группировки не произойдет и будет варнинг\n",
        "заменяем редкие значения на 'Rare'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFjTWC3gkIv6"
      },
      "source": [
        "def encode_rare(X_train, X_test, cols, min_val=0.05, n_cat=1):\n",
        "  encoder = ce.RareLabelCategoricalEncoder(tol=min_val, variables=cols, n_categories=n_cat, replace_with='Rare')\n",
        "  # fit the encoder Learns the frequent categories for each variable\n",
        "  X_train =  encoder.fit_transform(X_train)\n",
        "  X_test = encoder.fit_transform(X_test)\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxFA04EJ0egb"
      },
      "source": [
        "## encode_tgmean\n",
        "Перекодирует категориальные переменные по mean таргета в категориях\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train = encode_tgmean(X_train, X_test, y_train, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD43KywVaJ2P"
      },
      "source": [
        "def encode_tgmean(X_train, X_test, y_train, cols=None):\n",
        "  # mean encoder Learns the mean value of the target for each category of the variable.\n",
        "  encoder = ce.MeanCategoricalEncoder(variables=cols)\n",
        "\n",
        "  # fit the encoder\n",
        "  encoder.fit(X_train, y_train)\n",
        "\n",
        "  # transform the data\n",
        "  X_test = encoder.transform(X_test)\n",
        "  X_train = encoder.transform(X_train)\n",
        "\n",
        "  for col in X_train.columns:\n",
        "    X_test[col] = X_test[col].fillna(value=X_train[col].mean(), inplace=False)\n",
        "  return X_train, X_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ego4ftn70neO"
      },
      "source": [
        "## encode_woe\n",
        "Перекодирование на основе Weight of evidence:\n",
        "\n",
        "log(частота события в классе/ частоса не-события в классе)\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train = encode_woe(X_train, X_test, y_train, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzzUOPXKbmpw"
      },
      "source": [
        "def encode_woe(X_train, X_test, y_train, cols=None):\n",
        "\n",
        "  # set up a weight of evidence encoder\n",
        "  woe_encoder = ce.WoERatioCategoricalEncoder(encoding_method='woe', variables=cols)\n",
        "\n",
        " # fit the encoder\n",
        "  woe_encoder.fit(X_train, y_train)\n",
        "\n",
        " # transform\n",
        "  X_train = woe_encoder.transform(X_train)\n",
        "  X_test = woe_encoder.transform(X_test)\n",
        "  \n",
        "  return X_train, X_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28NmuHd_08f-"
      },
      "source": [
        "## encode_dtree\n",
        "Категориальная сначала энкодится в ordinal, затем они заменяютя предиктами decision tree\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train = encode_dtree(X_train, X_test, y_train, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfMnNngUiRMI"
      },
      "source": [
        "def encode_dtree(X_train, X_test, y_train, cols=None):\n",
        "  # set up the encoder\n",
        "  # replaces categories in the variable with the predictions of a decision tree\n",
        "  encoder = ce.DecisionTreeCategoricalEncoder(random_state=0, variables=cols)\n",
        "\n",
        "  # fit the encoder\n",
        "  encoder.fit(X_train, y_train)\n",
        "  \n",
        "  # transform the data\n",
        "  X_train = encoder.transform(X_train)\n",
        "  X_test = encoder.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9NV_PRfksHA"
      },
      "source": [
        "## encode_cb\n",
        "(countInclass + y.mean)/ (totalCount + a)\n",
        "\n",
        "mean encoding с Additive smoothing, коэф a = 1, менять его нет необходимости\n",
        "\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train = encode_cb(X_train, X_test, y_train, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3bKzzYjRNsr"
      },
      "source": [
        "def encode_cb(X_train, X_test, y_train, col=None):\n",
        "  # set up the encoder\n",
        "  # replaces categories in the variable with the predictions of a decision tree\n",
        "  encoder = CatBoostEncoder(cols=col)\n",
        "\n",
        "  # fit the encoder\n",
        "  encoder.fit(X_train, y_train)\n",
        "  \n",
        "  # transform the data\n",
        "  X_train = encoder.transform(X_train)\n",
        "  X_test = encoder.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XibnB6WH1T2r"
      },
      "source": [
        "## encode_cbfold\n",
        "Разбивает train на 5 частей, для каждой части находит mean с помощью CatBoost, исходя из оставшихся частей.\n",
        "\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train, y_test = cb_fold(X_train, X_test, y_train, y_test, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0yl6d_6AqD6"
      },
      "source": [
        "class TargetEncoderCV(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, colns, cv, **cbe_params):\n",
        "        self.cv = cv\n",
        "        self.colns = colns\n",
        "        self.cbe_params = cbe_params\n",
        "\n",
        "    @property\n",
        "    def _n_splits(self):\n",
        "        return check_cv(self.cv).n_splits\n",
        "\n",
        "    def fit_transform(self, X: pd.DataFrame, y) -> pd.DataFrame:\n",
        "        self.cbe_ = []\n",
        "        cv = check_cv(self.cv)\n",
        "\n",
        "        cbe = CatBoostEncoder(\n",
        "            cols=self.colns,\n",
        "            return_df=False,\n",
        "            **self.cbe_params\n",
        "        )\n",
        "        X_transformed = np.zeros_like(X[self.colns], dtype=np.float64)\n",
        "        for train_idx, valid_idx in cv.split(X, y):\n",
        "          self.cbe_.append(\n",
        "              clone(cbe).fit(X[self.colns].loc[train_idx], y[train_idx])\n",
        "              )\n",
        "          X_transformed[valid_idx] = self.cbe_[-1].transform(X[self.colns].loc[valid_idx])\n",
        "\n",
        "        return pd.concat([X.drop(self.colns, axis=1),\n",
        "                          pd.DataFrame(X_transformed, columns=self.colns)], axis=1)\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X_transformed = np.zeros_like(X[self.colns], dtype=np.float64)\n",
        "        for cbe in self.cbe_:\n",
        "            X_transformed += cbe.transform(X[self.colns]) / self._n_splits\n",
        "        return pd.concat([X.drop(self.colns, axis=1),\n",
        "                          pd.DataFrame(X_transformed, columns=self.colns)], axis=1)\n",
        "\n",
        "def encode_cbfold(X_train, X_test, y_train, y_test, cols=None):\n",
        "  te_cv = TargetEncoderCV(cols, KFold(n_splits=5))\n",
        "  X_train = X_train.reset_index(drop=True)\n",
        "  y_train = y_train.reset_index(drop=True)\n",
        "  X_test = X_test.reset_index(drop=True)\n",
        " ## y_test = y_test.reset_index(drop=True)\n",
        "  \n",
        "  X_train = te_cv.fit_transform(X_train, y_train)\n",
        "  X_test = te_cv.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXgC-x9ZMuUr"
      },
      "source": [
        "## encode_helm\n",
        "https://contrib.scikit-learn.org/category_encoders/_modules/category_encoders/helmert.html#HelmertEncoder\n",
        "\n",
        "Категориальная сначала переводится в Ordinal, а потом высчитывается mean на основе сравнения с mean \"оставшихся категорий\"\n",
        "\n",
        "Например mean категории А, сравнивается с B, C, D\n",
        "B с C,D  и т.д. На основе этого строится матрица хелмерта и по ней создаются новые категориальные переменные (как в OHE) https://www.ibm.com/support/knowledgecenter/en/SSLVMB_24.0.0/spss/common/catvar_coding_helmert.html\n",
        "\n",
        "Наиболее полезен, когда категориальные переменные упорядочнены от мнеьшего к большему, или наоборот\n",
        "\n",
        "\n",
        "cols - колонки, к которым применить\n",
        "\n",
        "Пример:\n",
        "X_train, X_test, y_train = encode_helm(X_train, X_test, y_train, [\"room\", \"temp\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6P706JwMvvR"
      },
      "source": [
        "def encode_helm(X_train, X_test, y_train, cols=None):\n",
        "  encoder = HelmertEncoder(cols=cols, handle_unknown='value', handle_missing='value').fit(X_train, y_train)\n",
        "  X_train = encoder.transform(X_train)\n",
        "  X_test = encoder.transform(X_test)\n",
        "  return X_train, X_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz9NP128w9qo"
      },
      "source": [
        "# Основной раздел"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWqv2QDmjHxE"
      },
      "source": [
        "## Загрузка данных\n",
        "для примера использовались категориальные данные \n",
        "https://www.kaggle.com/c/cat-in-the-dat/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzLOC8w8jHOJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUD96Jf4rUT-"
      },
      "source": [
        "!kaggle competitions download -c house-prices-advanced-regression-techniques -p /drive/kaggle/houseprices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VMOMSjs0Ey4"
      },
      "source": [
        "df=pd.read_csv(\"/drive/kaggle/houseprices/train.csv\")\r\n",
        "df1=pd.read_csv(\"/drive/kaggle/houseprices/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbSJcwmO1KKP"
      },
      "source": [
        "df.drop(['Id'], axis=1)\r\n",
        "df1.drop(['Id'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZb3L_GKgPit"
      },
      "source": [
        "\n",
        "target=df[\"SalePrice\"]\n",
        "features=df.drop(['SalePrice', ], axis=1)\n",
        "dfall=pd.concat([X_train, TEST])\n",
        "dfall.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4eOz3GY5az6"
      },
      "source": [
        "df.head(5)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3L__DbTXb1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQZDQtZ_59Fd"
      },
      "source": [
        "corrmat = df.corr()\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 17))\r\n",
        "sns.barplot(y=corrmat['SalePrice'].sort_values().index, x=corrmat['SalePrice'].sort_values().values)\r\n",
        "plt.xlabel(f'correlation between SalePrice')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsaKn9B-gfnG"
      },
      "source": [
        "cat_col=[c for c in df.columns if df[c].dtypes=='object']\n",
        "n_levels=df[cat_col].nunique()\n",
        "print(\"cardinality of categorical columns:\\n\",n_levels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myutGHP7RuxF"
      },
      "source": [
        "def fill_missing_data(df: pd.DataFrame):\r\n",
        "    for col_ in df.columns:\r\n",
        "        if df[col_].dtype == 'object':\r\n",
        "            # fill mode for categorical features\r\n",
        "            df[col_].fillna('Rare', inplace=True)\r\n",
        "        else:\r\n",
        "            # fill median for numerical features\r\n",
        "            df[col_].fillna(df[col_].median(), inplace=True)\r\n",
        "        \r\n",
        "fill_missing_data(df)\r\n",
        "fill_missing_data(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VGI0eNNjAGa"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features,target,test_size=0.4,random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GQx_D7X1u4m"
      },
      "source": [
        "X_train = features\r\n",
        "X_test = df1\r\n",
        "y_train = target\r\n",
        "y_test = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzbhyoND6Yyg"
      },
      "source": [
        "## Пример работы с функциями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqer3KBz30eG"
      },
      "source": [
        "high_cardinal=[c for c in cat_col if features[c].nunique()>50]\n",
        "low_cardinal=list(set(cat_col)-set(high_cardinal))\n",
        "\n",
        "X_train, X_test = encode_ohe(X_train, X_test, low_cardinal);\n",
        "cat_col=list(set(cat_col)-set(low_cardinal))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y8ptPSRvaqW"
      },
      "source": [
        "print(low_cardinal) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-FTp942gsX"
      },
      "source": [
        "def models_test(X_train, X_test, y_train, y_test, model_type=1, en_type='TEST', _plots=False, C_par=1.0): \r\n",
        "\r\n",
        "  xgb = XGBRegressor()\r\n",
        "\r\n",
        "  # test_size = 0\r\n",
        "  xgb.fit(X_train, y_train)\r\n",
        "  print('R^2 =', xgb.score(X_train, y_train))\r\n",
        "\r\n",
        "  pred = xgb.predict(X_test)\r\n",
        "    \r\n",
        "  subm_df = pd.read_csv('/drive/kaggle/houseprices/sample_submission.csv')\r\n",
        "  subm_df['SalePrice'] = pred\r\n",
        "  subm_df.to_csv(f'{en_type}_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi7IK_rAWzS7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = encode_cbfold(X_train, X_test, y_train, y_test, cols=cat_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEV4tzG02scz"
      },
      "source": [
        "models_test(X_train, X_test, y_train, y_test, en_type='cbfold_logreg_hp', _plots=True, C_par=4.690615956503463)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea0yZoDWk6yk"
      },
      "source": [
        "xgb = XGBRegressor()\r\n",
        "\r\n",
        "# test_size = 0\r\n",
        "xgb.fit(X_train, y_train)\r\n",
        "print('R^2 =', xgb.score(X_train, y_train))\r\n",
        "\r\n",
        "ypred = xgb.predict(X_test)\r\n",
        "print('Score =', metrics.mean_squared_error(np.log(y_test), np.log(ypred), squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzN5XwXLt1tU"
      },
      "source": [
        "models_test(X_train, X_test, y_train, y_test, en_type='cb', _plots=True)\n",
        "#cb_fold LogisticRegression ROC_AUC= 0.793521519143426  helmert+ohe+cb_fold\n",
        "#cb_fold LogisticRegression ROC_AUC= 0.7932658732871862 ohe+cb_fold(onlycat)\n",
        "#cb_fold LogisticRegression ROC_AUC= 0.7963710225797453 cb_fold\n",
        "#cb_fold LogisticRegression ROC_AUC= 0.7960390000124247 ohe+cb_fold(all)\n",
        "#cb LogisticRegression ROC_AUC= 0.7743017494958631 ohe+cb only use\n",
        "#cb LogisticRegression ROC_AUC= 0.774775144144356 helmert+ohe+cb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSjoTE4yM0NX"
      },
      "source": [
        "models_test(X_train, X_test, y_train, y_test, 2, en_type='cb_fold', _plots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGJIHzObOEdE"
      },
      "source": [
        "clf=LogisticRegression(C=1, solver=\"lbfgs\", max_iter=5000) \r\n",
        "clf.fit(X_train, y_train)\r\n",
        "print('LogisticRegression ROC_AUC=', \r\n",
        "      metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVXnVF9Z3z1k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}